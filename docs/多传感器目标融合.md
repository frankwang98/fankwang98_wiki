# MSF多传感器融合感知

## 一、前言

多传感器融合（Mult-Sensor Fusion，MSF）是指利用传感器技术、计算机和人工智能技术，将来自多源传感器的信息以一定的准则进行分析和综合，从而为决策和估计提供精准数据的一种必要的信息处理过程。与人类感知外界环境类似，多源传感器都有其不可替代的优势，因此有必要对多种传感器进行多层次的信息互补和优化处理，最终形成对探测环境的一致性认知。

多传感器融合的前提是多个传感器的时间和空间同步，有硬同步和软同步两种方法。

多传感器融合根据信息融合的级别可以分为数据级别融合（前融合）、特征级别融合和目标级别融合（后融合/决策融合），需要根据应用场景的不同选择适合的信息融合方式。

多传感器融合的主要应用方向是多目标检测，其优势在于不同传感器之间可以进行信息互补，提高感知结果的准确性和鲁棒性。

本文对一款混合固态激光雷达和一种低成本相机的感知融合，通过相机与激光雷达的联合标定实现时空同步，基于深度学习方法在车辆平台和路侧平台进行多目标融合检测，并与单一传感器检测效果进行对比，证明多传感器融合感知结果准确性和鲁棒性更高。

## 二、多传感器融合方法

多传感器融合的基本原理是将多种传感器进行多层次、多空间的信息互补和优化组合处理，最终形成对探测环境的一致性认知。

我们都知道，对传感器数据的处理流程一般有获得数据、提取特征、识别目标三个步骤，由此产生了多传感器信息融合的三种方法，即数据融合方法、特征融合方法和目标融合方法。

数据融合方法是指对融合后的多维数据进行统一感知算法处理的方法。

特征融合方法属于中间层的融合，即先从每个传感器提供的原始数据中提取代表性的特征，再把这些特征融合成单一的特征向量，其中选择合适的特征进行融合是关键，特征信息包括边缘、方向、速度、形状等。（数据融合和目标融合目前只是概念，实际算法设计其实是特征融合）

特征层融合根据融合特征的性质不同又可划分为两大类：目标状态融合（特征前融合）、目标特征融合（特征后融合）。

目标状态融合主要应用于多目标跟踪领域，融合系统首先对传感器数据进行预处理以完成数据配准，在数据配准后实现参数关联和状态估计。（数据配准）

目标特征融合就是特征层联合识别，它的实质就是模式识别问题，在融合前必须先对特征进行关联处理，再对特征矢量分类成有意义的组合。（特征匹配）

在目标融合方法中，每种传感器都会输出独立的感知结果，而目标融合就是指综合各传感器的目标级感知结果，再由主处理器进行数据融合的方法。

在融合的三个层次中，特征层融合技术发展较为完善，并且由于在特征层已建立了一整套的行之有效的特征关联技术，可以保证融合信息的一致性，此级别融合对计算量和通信带宽要求相对降低，但由于部分数据的舍弃使其准确性也有所下降。

总的来说，从数据级融合到目标级融合，对计算量和通信带宽的要求依次下降，同时感知结果的准确性也会逐级下降，因此，需要根据应用场景和主机性能的不同选择合适的信息融合方法。


## 三、多传感器联合标定

多传感器融合首先需要多个传感器的时间和空间同步，即时间戳和坐标系的统一。

时空同步主要有硬同步和软同步两种方法。硬同步是指硬件同步，即根据传感器状态信息，在硬件中同时发布数据采集指令，实现各传感器采集的时间同步，这种方案可以大大降低时间同步误差，但需要重新设计硬件，难度较大。软同步是指软件同步，又分为软件时间同步和软件空间同步，软件时间同步是指通过统一的主机确定各传感器的基准时间，各传感器的数据信息会自带时间戳信息，实现时间戳同步；软件空间同步是将不同传感器的数据通过坐标变换统一到同一坐标系下，在运动场景如车辆运动过程中还需要考虑当前速度下的帧内位移校准。

具体步骤如下：首先标定摄像头，获得其内参矩阵；然后用Autoware与RViz工具通过多组点云和图像的重投影解算，获得激光雷达坐标系与摄像头坐标系之间的旋转矩阵和平移矩阵，实现两者的外参标定，即空间同步；接着以激光雷达时间戳为基准，摄像头向激光雷达配准实现两者的时间同步。标定完成后，激光雷达点云能较好地投影到相机图像上。

## 四、基于车辆和路侧平台的多目标融合检测

基于多传感器路侧平台进行多目标检测对于车路协同很有意义，可以将计算量从车端转移到路端，同时由于路侧平台的视野范围更大，可以将更多的目标信息传递给车端。

多目标融合检测的基本思路是：首先需要将摄像头和激光雷达进行联合标定，获取两者坐标系的空间转换关系，然后把激光雷达投射到图像的坐标系中，建立图像的像素点，和激光雷达投影后的点之间做匹配；数据融合后图像上会显示激光雷达的深度信息；在多目标检测时，障碍物的检测可以使用激光雷达进行物体聚类，但是对于较远物体稀疏的激光线数聚类的效果较差，因此利用视觉图像信息进行目标检测，进而获取障碍物的位置，同时视觉还可以给出障碍物类别信息。

基于智能驾驶车辆平台和移动车路协同平台，设计了激光雷达与摄像头融合的环境感知算法，兼顾了检测精度和实时性。

具体方法如下：

激光雷达：PointPillars（设计一种轻量化点云分类网络）

使用雷达进行环境感知的传统步骤包括获取雷达数据、预处理（滤波、地面点去除）、创建地图（栅格地图/3D地图）、聚类（基于划分、密度、网格）、ROI提取（网格法聚类、栅格地图投影到图像、动态阈值放大远处物体、合并ROI）、识别（降低置信度，融合两者分类，据此准备数据集，设计点云分类网络）、跟踪（卡尔曼滤波求最优值，降低误差）。

摄像头：Yolo（改进定位、检测精度）

图像检测一般有传统方法和深度学习方法两种，前者一般是设计模型特征，进行分类，属于手动特征提取，而后者则是利用机器自我学习训练的思路。

融合感知：MV3D、AVOD（改进OC3D-AVOD）

融合方式选择：特征融合（首选成熟）、数据融合（车辆平台）、目标融合（路侧平台）

目标融合方法（特征后融合）：结合点云聚类和目标检测的优势，设计一种针对目标区域范围点云的分类神经网络，然后基于IOU进行图像和点云的目标匹配，将视觉检测与点云分类的结果进行软加权平均，得出最终检测结果。实验证明在车辆、行人检测中效果很好。

数据融合方法（特征前融合）：采用融合感知算法直接对相机图像和雷达点云进行实时处理。基于多视图即点云俯视图（BEV）、点云前视图和前摄像头图像进行特征融合。

实际上，车路协同（V2X）技术中一个关键点就是将车辆平台和路侧平台的感知数据对同一目标进行最终的结果融合，使融合后的结果具有唯一性且置信度高，真正实现了数据的决策融合感知和交互共享。基于车路协同的感知融合算法属于后融合算法。

## 五、与单一传感器检测结果对比

单一传感器检测结果

多传感器检测结果

## 六、总结

预期结果，多传感器检测结果更好。

融合感知算法将广泛应用于路端和车端设备，主要解决障碍物错检漏检以及夜间感知的问题。

未来可以使用更加快速、准确、健壮的多目标检测算法，并进行工程化部署。

V2X技术也将先从感知融合与交互上进行突破。